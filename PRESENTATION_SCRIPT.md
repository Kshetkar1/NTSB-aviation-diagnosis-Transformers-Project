# Presentation Script: Aviation Incident Diagnosis Engine
## 11 Minute Word-for-Word Script

**Total Words:** ~1,259 (11:10 minutes at 150 words/min)
**Author:** Kanu Shetkar

---

## Instructions:
- Read only the "SAY THIS" sections word-for-word
- Follow screen directions at the start of each section
- Practice timing: Should be ~11 minutes total
- Don't rush - clear articulation is important

---

## **INTRODUCTION (25 seconds - 65 words)**

**ðŸ“º SCREEN:**
- Show README_PRESENTATION.md title

**SAY THIS:**

December 28th, 2016. American Airlines Flight 383 catches fire during takeoff at Chicago O'Hare. All passengers evacuate safely, but investigators face a challenge: searching eighty thousand historical incidents to find similar engine fire cases. This manual analysis takes hours.

I'm Kanu Shetkar. My Aviation Incident Diagnosis Engine does this search in seconds using transformer embeddings and LLM agents, demonstrating how transformers enable safety-critical applications while mitigating hallucination risks.

---

## **SECTION 1: PROBLEM STATEMENT (50 seconds - 130 words)**

**ðŸ“º SCREEN:**
- Scroll to "1. Problem Statement & Overview"
- Point to architecture diagram when mentioned

**SAY THIS:**

Aviation safety analysts must search the NTSB databaseâ€”over eighty thousand aviation incidents since 1962â€”to investigate patterns. Manual analysis takes hours. Traditional keyword search fails because semantically identical descriptions use different words: "engine fire during takeoff" won't match "smoke from engine compartment on departure"â€”same phenomenon, different words.

Why not just ask an LLM? LLMs hallucinate facts, generating plausible diagnoses not grounded in real data. For life-or-death aviation decisions, this is unacceptable.

My hybrid architecture delivers diagnoses in seconds, not hours. It uses transformers for semantic understanding but deterministic tools for facts. Three components: an LLM agent for orchestration, a diagnostic tool for semantic search and similarity-weighted aggregation, and the NTSB database with pre-computed embeddings.

---

## **SECTION 2: METHODOLOGY (3 minutes 25 seconds - 602 words)**

### **Part A: Transformer Embeddings (1 minute 5 seconds - 162 words)**

**ðŸ“º SCREEN:**
- Scroll to "2.1 Transformer Embeddings"
- Point to code snippet when mentioned
- Point to example "engine fire during takeoff"

**SAY THIS:**

Let me explain how transformer concepts enable this system.

First, transformer embeddings solve the core aviation safety problem. Traditional keyword search fails because "engine fire during takeoff" and "smoke from engine compartment on departure" share zero keywords, yet describe identical failure modes.

I use text-embedding-3-small to convert incident narratives into fifteen-hundred-thirty-six dimensional semantic coordinates. Why does this work? How did the transformer learn these semantic relationships?

During pre-training on billions of text examples, the model learned to predict masked words. To correctly predict "fire" from surrounding context, it had to learn that "smoke," "combustion," and "flames" appear in similar contexts. This forces the architecture to position semantically related words close together in vector spaceâ€”not through manual rules, but through statistical patterns in language.

My query "engine fire during takeoff" now finds incidents with completely different wordingâ€”"fire in engine compartment," "smoke from engine," "combustion event during climb"â€”because they're close in semantic vector space, not keyword space. This is the fundamental advantage: transformers capture meaning, not just words.

---

### **Part B: Transformer Architecture Fundamentals (20 seconds - 50 words)**

**ðŸ“º SCREEN:**
- Scroll to "2.2 Transformer Architecture: Why Transfer Learning Works"
- Point to Multi-Head Attention algorithm when mentioned

**SAY THIS:**

Second, why does this transfer learning work without aviation-specific fine-tuning? Multi-head attention is keyâ€”here's the formal algorithm. Different attention heads specialize in different semantic dimensionsâ€”combustion terms, aircraft components, emergency terminology. This automatic decomposition of meaning explains why semantic search achieves eighty-eight percent precision versus forty-two percent for keywords.

---

### **Part C: Attention-Inspired Similarity Search (20 seconds - 50 words)**

**ðŸ“º SCREEN:**
- Scroll to "2.3 Attention-Inspired Similarity"
- Point to algorithm when mentioned

**SAY THIS:**

Third, adapting attention principles for document-level similarity. Just as attention uses dot productsâ€”Q times K-transposeâ€”I use cosine similarity to measure how aligned query and incident vectors are in semantic space. This computes similarity against all eighty thousand NTSB incidents, returning the top fifty ranked by relevance.

---

### **Part D: Similarity-Weighted Aggregation (1 minute 20 seconds - 190 words)**

**ðŸ“º SCREEN:**
- Scroll to "2.4 Similarity-Weighted Aggregation"
- Point to formula when mentioned

**SAY THIS:**

Fourth, similarity-weighted aggregationâ€”this is my key innovation adapting attention-style weighting to diagnostic reasoning.

Here's the problem: I have forty-three similar incidents, each with different root causes. How do I combine this evidence? Why not just count causes?

Because relevance matters more than frequency. Imagine ten incidents cite "pilot error" but they're only sixty percent similar to my queryâ€”that's a total weight of six-point-zero. Now imagine five incidents cite "mechanical failure" but they're ninety-five percent similarâ€”that's a weight of four-point-seven-five.

Simple counting would say "pilot error" is more likely because ten is greater than five. But my weighted approach correctly recognizes that the five highly-similar mechanical failures are more relevant evidence than ten loosely-similar pilot errors.

Why this approach? Because similarity scores represent evidence strength. A ninety-five percent similar incident is much stronger evidence than a sixty percent similar oneâ€”it should contribute proportionally more to the probability. This treats similarity as confidence weights, just like attention mechanisms weight tokens by relevance.

The formula: weighted probability of cause j equals sum of similarities where that cause appears, divided by sum of all similarities. This ensures probabilities sum to one while respecting evidence quality.

---

### **Part E: LLM Function Calling (1 minute - 150 words)**

**ðŸ“º SCREEN:**
- Scroll to "2.5 LLM Function Calling"
- Point to three-step workflow diagram when mentioned

**SAY THIS:**

Finally, LLM function callingâ€”this orchestrates the system while preventing hallucination.

My agent has three steps. Step one: the LLM generates a detailed NTSB-style incident report from the brief query, demonstrating generation capability.

Step two: the LLM calls my diagnostic tool for factual data. This is function callingâ€”the LLM doesn't generate the diagnosis, it retrieves it. The tool executes the semantic search and similarity-weighted aggregation, returning statistical results from real historical data.

Step three: the LLM synthesizes these tool results into plain English. It interprets the statistics but doesn't invent factsâ€”everything is grounded in tool output.

Three API calls implement this: generation, tool call with diagnostic function defined, and synthesis.

This demonstrates separation of concerns: the LLM handles orchestration and explanation, the tool handles facts. The diagnosis cannot be hallucinated because it's retrieved from historical data, not generated.

---

## **SECTION 3: DEMO (1 minute - 150 words)**

**ðŸ“º SCREEN:**
- Switch to Streamlit app at localhost:8501
- Enter query "engine fire during takeoff" and click "Run Diagnostic Agent"
- Focus on Output 2 (diagnostic results)

**SAY THIS:**

Let me demonstrate this system in action. Query: "engine fire during takeoff."

The Streamlit interface shows three outputs. Output one: LLM-generated NTSB-style incident synopsis.

Output twoâ€”the critical diagnostic resultsâ€”shows factual data from historical analysis, not hallucinations.

The system found forty-three similar historical incidents. The top three causes each have four percent probability: maintenance personnel installation issues, engine turbine section failure, and turbine section fatigue and corrosionâ€”each appearing in three of the forty-three similar incidents.

Each probability uses similarity-weighted aggregationâ€”more similar incidents contribute more weight.

Output three: LLM synthesis interpreting the statistics in plain English.

This demonstrates the complete transformer pipeline: embeddings enabled semantic search finding forty-three relevant cases, attention-inspired similarity ranked them by relevance, and weighted aggregation calculated evidence-based probabilities. LLM orchestration with deterministic factual grounding.

---

## **SECTION 4: EVALUATION (1 minute 5 seconds - 187 words)**

**ðŸ“º SCREEN:**
- Switch back to README, scroll to "4. Assessment & Evaluation"
- Point to Performance Evaluation table
- Point to model architecture table
- Point to Intended Uses section
- Point to Ethical Considerations section
- Briefly show model cards tables at end

**SAY THIS:**

Let me cover evaluation and model cards.

I evaluated semantic search against keyword baseline using five test queries. Methodology: for each query, I manually reviewed top-ten results and labeled them relevant or irrelevant based on whether they described similar incident types.

Results: semantic search achieved eighty-eight-point-three percent average precision versus forty-two percent for keyword matchingâ€”a two-point-one-times improvement. This improvement was consistent across all test queries, suggesting systematic advantage rather than chance. For "engine fire during takeoff," semantic search found "smoke from engine compartment on departure"â€”keyword search missed it. This validates transformer embeddings capture semantics, not just lexical matching.

Two models power this: GPT-4-o-mini for generation, orchestration, and synthesis, and text-embedding-3-small for semantic similarity with fifteen-hundred-thirty-six dimensions.

This system is appropriate for research, historical pattern analysis, and educational demonstration of hybrid AI. It's not intended for real-time flight operations or regulatory compliance without validation. It provides probabilities, not certaintiesâ€”it supports expert analysis but doesn't replace it.

Ethical considerations: The historical data may reflect reporting biases. My mitigation is the weighted approach that accounts for relevance. LLM hallucinations are mitigated because the diagnostic facts come from the tool, not generation. For safety-critical domains, this is educational use only and requires expert validation.

Complete model and data cards are in the README with licenses, documentation links, and specifications.

---

## **SECTION 5: CRITICAL ANALYSIS (45 seconds - 115 words)**

**ðŸ“º SCREEN:**
- Scroll to "6. Critical Analysis"

**SAY THIS:**

Impact: diagnoses in seconds versus hours, grounded in historical data.

Two key insights: First, transfer learning worksâ€”transformers trained on general text transfer to aviation without fine-tuning, capturing fundamental semantic structures.

Second, the hallucination-accuracy tradeoff. LLM generation enables synthesis but risks hallucination. Embeddings enable factual retrieval. Solution: hybrid architectureâ€”LLMs for orchestration, embeddings for grounding.

Current limitations: Three main ones. First, evaluation is small-scale with only five test queriesâ€”needs larger validation. Second, no temporal analysis of trends over time. Third, no uncertainty quantification for the probabilities.

Future work has three priorities: short-term, validate with NTSB analysts. Medium-term, implement FAISS for scalability to millions of incidents. Long-term, add temporal trend analysis and predictive modeling for emerging risks.

---

## **SECTION 6: WRAP-UP (20 seconds - 50 words)**

**ðŸ“º SCREEN:**
- Scroll to bottom showing Repository link
- Show GitHub URL prominently

**SAY THIS:**

In summary: transformer architecturesâ€”embeddings, attention, and function callingâ€”enable responsible safety-critical AI applications.

Code, model cards, and documentation: https://github.com/Kshetkar1/NTSB-aviation-diagnosis-Transformers-Project.

Thank you. Questions?

---

## **END OF PRESENTATION**

**Total Duration:** ~11:25 minutes
**Word Count:** ~1,299 words
