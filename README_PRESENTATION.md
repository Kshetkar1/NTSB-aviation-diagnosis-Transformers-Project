# Aviation Incident Diagnosis Engine: Transformers for Safety Analysis

**Author:** Kanu Shetkar
**Repository:** https://github.com/Kshetkar1/NTSB-aviation-diagnosis-Transformers-Project

---

## Abstract

This project demonstrates how transformer embeddings, LLM function calling, and weighted Bayesian analysis can diagnose probable root causes of aviation incidents. Rather than relying on LLMs to generate safety-critical facts (which risks hallucinations), we use transformers as intelligent orchestratorsâ€”coordinating semantic search with deterministic diagnostic tools to produce reliable, explainable results from historical NTSB data.

**Key Innovation:** Similarity-weighted evidence aggregation where transformer attention mechanisms meet Bayesian reasoning.

---

## 1. Problem Statement & Overview (10 pts)

### The Challenge

Aviation safety analysts must search thousands of NTSB incident reports to identify probable root causes. **Keyword search fails** because semantically similar descriptions use different words:
- "engine fire during takeoff" â‰  "smoke from engine compartment on departure"
- Yet both describe the same phenomenon

**Why not just ask an LLM?** LLMs can hallucinate factsâ€”unacceptable for safety-critical applications.

### The Solution: Hybrid Transformer Architecture

```mermaid
graph LR
    A["ğŸ” User Query"] --> B["ğŸ¤– LLM Agent<br/>GPT-4o-mini"]

    B --> C["1ï¸âƒ£ Generate<br/>Report"]
    C --> D["2ï¸âƒ£ Call<br/>Tool"]
    D --> E["ğŸ”§ Diagnostic<br/>Tool"]

    E --> F["ğŸ“Š Semantic<br/>Search"]
    E --> G["ğŸ“ˆ Weighted<br/>Bayesian"]

    F --> H["ğŸ’¾ NTSB Data<br/>1536-dim"]
    G --> H

    H --> I["ğŸ“‹ Results"]
    I --> D
    D --> J["3ï¸âƒ£ Synthesize"]
    J --> K["âœ… Final<br/>Diagnosis"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style C fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style E fill:#fce4ec,stroke:#c2185b,stroke-width:3px
    style F fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style G fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style H fill:#e0f2f1,stroke:#00796b,stroke-width:3px
    style J fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style K fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
```

**Architecture Principles:**
1. Transformers for semantic understanding (embeddings)
2. LLMs as orchestrators (not fact generators)
3. Deterministic tools for verifiable facts
4. Weighted aggregation (attention-inspired)

---

## 2. Methodology: Transformers in Action (50 pts)

### 2.1 Transformer Embeddings: Semantic Vector Spaces

**Theoretical Foundation** (Phuong & Hutter, 2022 - Formal Algorithms):

```
Algorithm: Token Embedding
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  v âˆˆ V (token)
Output: e âˆˆ â„^d_e (vector)
Parameters: W_e âˆˆ â„^(d_e Ã— |V|)

return e = W_e[:, v]
```

**Our Extension:** Document-level embeddings using OpenAI text-embedding-3-small:

```python
def get_embedding(text: str) -> np.ndarray:
    """Maps incident narrative to semantic vector space (â„^1536)"""
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    return response.data[0].embedding
```

**Why it works:** Transformer self-attention learns semantic relationships during pre-training.

**Example:**
```
Query: "engine fire during takeoff" â†’ [0.023, -0.145, ..., 0.034] (1536-dim)

Top Matches (by semantic meaning):
1. "fire in engine compartment on departure"  â†’ 0.87 similarity
2. "smoke observed from engine during climb"  â†’ 0.82 similarity
3. "engine failure shortly after takeoff"     â†’ 0.79 similarity
```

### 2.2 Transformer Architecture: Key Components

**Multi-Head Attention Mechanism** (Vaswani et al., 2017):

The transformer uses multi-head attention to capture different types of relationships:

```
Algorithm: Multi-Head Attention (Phuong & Hutter, Alg 5)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  X âˆˆ â„^(dÃ—n) (sequence of n tokens)
Parameters: H attention heads
           W_q^h, W_k^h, W_v^h for each head h âˆˆ [H]
           W_o (output projection)

For each head h âˆˆ [1..H]:
    Q^h = W_q^h X    (query projections)
    K^h = W_k^h X    (key projections)
    V^h = W_v^h X    (value projections)

    Y^h = Attention(Q^h, K^h, V^h)
           = softmax(Q^h K^h^T / âˆšd_k) V^h

Y = W_o [Y^1; Y^2; ...; Y^H]    (concatenate & project)

return Y
```

**Why Multi-Head?** Different heads learn different relationships:
- Head 1 might learn syntactic relationships (subject-verb)
- Head 2 might learn semantic relationships (synonyms)
- Head 3 might learn positional relationships (adjacent words)

**Application to Aviation Safety:** When text-embedding-3-small embeds "engine fire," its multi-head architecture activates different heads for combustion semantics, aircraft component relationships, and emergency terminology. The model distills these parallel representations into a single 1536-dimensional vector encoding all relationship types simultaneously.

**Positional Embeddings** (Critical for Sequential Data):

Transformers have no inherent notion of order. Positional embeddings add sequence information:

```
Algorithm: Positional Embedding (Phuong & Hutter, Alg 2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  t âˆˆ [1..n] (position in sequence)
Output: e_p âˆˆ â„^d_e (positional embedding)

Learned approach:
    W_p âˆˆ â„^(d_e Ã— max_len)
    e_p = W_p[:, t]

Sinusoidal approach (Vaswani et al.):
    PE(t, 2i)   = sin(t / 10000^(2i/d))
    PE(t, 2i+1) = cos(t / 10000^(2i/d))

Final embedding: e_total = e_token + e_position
```

**Our Application:** While we don't explicitly use positional embeddings for document-level embeddings, the underlying text-embedding-3-small model learned positional information during pre-training to understand token order within incidents.

**Layer Normalization** (Stable Training):

```
Algorithm: Layer Norm (Phuong & Hutter, Alg 6)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  x âˆˆ â„^d (activations)
Parameters: Î³, Î² âˆˆ â„^d (scale & shift)

Î¼ = Î£x[i] / d                    (mean)
ÏƒÂ² = Î£(x[i] - Î¼)Â² / d            (variance)
xÌ‚ = (x - Î¼) / âˆš(ÏƒÂ² + Îµ)         (normalize)

return Î³ âŠ™ xÌ‚ + Î²                 (scale & shift)
```

Layer norm ensures stable gradients during training, critical for deep transformers (GPT-4o-mini has many layers).

### 2.3 Attention-Inspired Similarity Search

**Attention Mechanism** (Vaswani et al., 2017):
```
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V
```

The `QK^T` dot product measures **relatedness** between queries and keys. The **âˆšd_k scaling** prevents softmax saturation in high dimensions, crucial for stable gradients during training.

**Our Adaptation:** Cosine similarity (normalized dot product):

```
Algorithm: Semantic Search
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  q âˆˆ â„^d (query embedding)
        D âˆˆ â„^(NÃ—d) (database embeddings)
Output: Ranked incidents

For each incident i:
    similarity[i] = (q Â· D[i]) / (||q|| Ã— ||D[i]||)

return top_k incidents by similarity
```

**Implementation:**
```python
def find_top_matches(query_embedding, embeddings, top_k=50):
    """O(NÂ·d) vectorized similarity search"""
    similarities = cosine_similarity([query_embedding], embeddings)[0]
    sorted_indices = np.argsort(similarities)[::-1]
    return similarities[sorted_indices[:top_k]]
```

**Connection to Attention:** Both use dot products to measure relationships, both aggregate information weighted by relevance.

**Visual: Attention-Inspired Similarity**
```mermaid
graph TD
    Q["Query Embedding<br/>engine fire during takeoff<br/>[0.02, -0.14, ..., 0.03]"] --> S[Cosine Similarity]

    D1["Incident 1<br/>fire in engine compartment<br/>[0.03, -0.15, ..., 0.04]"] --> S
    D2["Incident 2<br/>smoke from engine<br/>[0.02, -0.13, ..., 0.03]"] --> S
    D3["Incident 3<br/>landing gear failure<br/>[-0.45, 0.78, ..., -0.12]"] --> S

    S --> R1["Similarity: 0.87 âœ…<br/>High relevance"]
    S --> R2["Similarity: 0.82 âœ…<br/>High relevance"]
    S --> R3["Similarity: 0.23 âŒ<br/>Low relevance"]

    R1 --> TOP["Top K<br/>Most Similar<br/>Incidents"]
    R2 --> TOP

    style Q fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style D1 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style D2 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style D3 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style S fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style R1 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style R2 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style R3 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style TOP fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
```

### 2.4 Similarity-Weighted Aggregation

**Problem:** How to aggregate diagnostic evidence from 50 similar incidents with different root causes?

**Solution:** Similarity-weighted probability (attention-inspired aggregation):

```
P_weighted(cause_j) = Î£_{i: cause_j âˆˆ C_i} sim(q, d_i) / Î£_{i=1}^{n} sim(q, d_i)
```

**Connection to Transformers:** More similar incidents contribute more to final probabilityâ€”same weighted aggregation principle as attention mechanism (high-attention tokens contribute more to outputs).

### 2.5 LLM Function Calling: Tool Orchestration

**Function Calling Paradigm:**
```
Traditional: User â†’ LLM â†’ [generated diagnosis] âŒ (hallucination risk)

Function Calling:
User â†’ LLM â†’ "I need to call diagnostic tool"
         â†“
    Tool â†’ [factual statistical results]
         â†“
    LLM â†’ [synthesizes + explains] âœ… (facts from tool)
```

**Three-Step Agent:**
```python
def run_diagnosis_agent(user_query):
    # Step 1: Generate detailed report (shows LLM capability)
    report = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"Generate synopsis: {user_query}"}]
    ).choices[0].message.content

    # Step 2: Tool call (demonstrates reasoning + function calling)
    tool_response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"Diagnose: {report}"}],
        tools=tools,
        tool_choice="auto"
    )

    # Execute tool
    results = diagnose_root_causes(report)

    # Step 3: Synthesize (demonstrates interpretation)
    final = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "tool", "content": json.dumps(results)}]
    ).choices[0].message.content

    return {report, results, final}
```

**Why This Matters:**
- **Separation:** LLM handles understanding/explanation, Tool handles facts
- **Reliability:** Diagnostic facts retrieved, not generated
- **Transparency:** Tool results separately visible

---

## 3. Implementation & Demo (20 pts)

### Key Algorithms

**Algorithm 1: Embedding Generation**
```python
# O(1) API call
embedding = client.embeddings.create(
    input=[text],
    model="text-embedding-3-small"
).data[0].embedding
```

**Algorithm 2: Weighted Diagnosis**
```python
# O(nÂ·c) where n=incidents, c=avg causes
def calculate_weighted_diagnosis(scores, matches, top_n=50):
    cause_evidence = defaultdict(list)

    for score, match in zip(scores[:top_n], matches[:top_n]):
        for cause in match['causes']:
            cause_evidence[cause].append(score)

    total = sum(sum(scores) for scores in cause_evidence.values())

    return [{
        'cause': cause,
        'probability': sum(scores) / total,
        'num_incidents': len(scores)
    } for cause, scores in cause_evidence.items()]
```

### Live Demo (Streamlit)

**Demo Flow:**
1. Enter: "engine fire during takeoff"
2. **Output 1:** LLM-generated detailed report
3. **Output 2:** Tool results (Top 10 causes with probabilities)
   - Example: "Fatigue/wear/corrosion: 32.4% (23 incidents, avg sim: 0.81)"
4. **Output 3:** LLM synthesis explaining results

**Run:** `streamlit run streamlit_app.py`

---

## 4. Assessment & Evaluation (15 pts)

### Model Architecture

| Component | Model | Purpose |
|-----------|-------|---------|
| **LLM** | GPT-4o-mini | Report generation, orchestration, synthesis |
| **Embeddings** | text-embedding-3-small | Semantic similarity (1536 dims) |
| **Context** | 128K tokens | Multi-turn reasoning |

### Performance Evaluation

**Validation Test:** 5 test queries compared against keyword search baseline

| Query Type | Semantic Search (Ours) | Keyword Search | Improvement |
|------------|------------------------|----------------|-------------|
| Synonymous terms | 92% relevant matches | 34% relevant matches | +58% |
| Paraphrased descriptions | 88% relevant matches | 21% relevant matches | +67% |
| Technical jargon | 85% relevant matches | 71% relevant matches | +14% |
| **Average Precision** | **88.3%** | **42.0%** | **+46.3%** |

**Methodology:** For each test query, manually reviewed top-10 results from both semantic and keyword search. Labeled each result as relevant or irrelevant based on whether it described a similar incident type (e.g., engine-related failures for "engine fire" queries). Calculated precision as (relevant results / total results).

**Key Finding:** Transformer embeddings capture semantic meaning, enabling 2.1x improvement in retrieval precision over keyword matching.

**Test Queries:**
1. "engine fire during takeoff" â†’ Found: "smoke from engine compartment on departure"
2. "bird strike on final approach" â†’ Found: "wildlife collision during landing sequence"
3. "hydraulic system failure" â†’ Found: "loss of hydraulic pressure in flight controls"
4. "turbulence injury" â†’ Found: "passenger injured during rough air encounter"
5. "fuel starvation" â†’ Found: "engine failure due to fuel exhaustion"

### Intended Uses âœ… & Limitations âŒ

**Appropriate:**
- âœ… Research and historical pattern analysis
- âœ… Educational demonstration of hybrid AI
- âœ… Supporting (not replacing) expert analysis

**Not Intended:**
- âŒ Real-time flight operations decisions
- âŒ Regulatory compliance without validation
- âŒ Definitive causal determinations (provides probabilities)

### Ethical Considerations

**Data Bias:** Historical NTSB data may reflect reporting biases
**Mitigation:** Weighted approach accounts for relevance, show supporting evidence

**LLM Hallucinations:** LLMs can generate false information
**Mitigation:** Tool provides factual data, LLM only interprets (not invents)

**Safety-Critical Domain:** Aviation decisions have life-or-death consequences
**Mitigation:** Educational use only, requires expert validation

---

## 5. Model & Data Cards (5 pts)

### Model Card: GPT-4o-mini

| Property | Value |
|----------|-------|
| **Provider** | OpenAI |
| **Architecture** | Decoder-only transformer |
| **Context** | 128,000 tokens |
| **Capabilities** | Generation, function calling, reasoning |
| **Usage** | Report generation, orchestration, synthesis |
| **Docs** | https://platform.openai.com/docs/models/gpt-4o-mini |

### Model Card: text-embedding-3-small

| Property | Value |
|----------|-------|
| **Dimensions** | 1536 |
| **Max Input** | 8191 tokens |
| **Use Case** | Semantic similarity, dense retrieval |
| **Usage** | Converting narratives to vectors |
| **Docs** | https://platform.openai.com/docs/guides/embeddings |

### Data Card: NTSB Aviation Database

| Property | Value |
|----------|-------|
| **Source** | National Transportation Safety Board |
| **License** | Public domain (U.S. government data) |
| **Size** | Thousands of incidents |
| **Format** | Structured JSON (post-processing) |
| **Access** | https://www.ntsb.gov/Pages/AviationQuery.aspx |

---

## 6. Critical Analysis (10 pts)

### Impact

**Aviation Safety:**
- Enables rapid pattern recognition (seconds vs. hours)
- Semantic search finds relevant cases with different terminology
- Evidence-based recommendations grounded in historical precedent

**Transformer Research:**
- Demonstrates practical hybrid architecture (embeddings + function calling + tools)
- Shows LLM hallucination mitigation for safety-critical domains
- Example of LLMs as orchestrators, not oracles

**Technical Innovation:**
- Similarity-weighted Bayesian combines semantic search with statistical aggregation
- Attention-inspired diagnosis applies transformer concepts outside model architecture

### What This Reveals

**About Transformers:**
- âœ… Embeddings excel at semantic understanding
- âœ… Function calling extends capabilities safely
- âœ… Multi-step reasoning handles complex tasks
- âŒ Generation alone insufficient for safety-critical facts

**About Hybrid AI:**
- LLM understanding + deterministic accuracy > either alone
- Use LLMs as coordinators, not knowledge sources

### Limitations & Next Steps

**Current Limitations:**
1. Evaluation is manual and small-scale (needs multi-rater validation and larger test set)
2. No temporal analysis (doesn't track trends over time)
3. No confidence intervals (probabilities lack uncertainty quantification)

**Future Work:**
- **Short-term:** Expert validation study, performance optimization (ANN search)
- **Medium-term:** Temporal analysis, causal chain visualization
- **Long-term:** Predictive modeling, multi-modal analysis

---

## 7. Documentation & Resources (5 pts)

### Setup

```bash
git clone https://github.com/Kshetkar1/NTSB-aviation-diagnosis-Transformers-Project.git
cd NTSB-aviation-diagnosis-Transformers-Project
pip install -r requirements.txt

# Add OpenAI API key
echo "OPENAI_API_KEY=your-key" > .env

# Run app
streamlit run streamlit_app.py
```

### Course-Relevant Papers

1. **"Attention Is All You Need"** (Vaswani et al., 2017)
   https://arxiv.org/abs/1706.03762
   *Relevance: Attention mechanism foundation*

2. **"Formal Algorithms for Transformers"** (Phuong & Hutter, 2022)
   https://arxiv.org/abs/2207.09238
   *Relevance: Embeddings (Alg 1), Attention (Alg 4-5), GPT (Alg 10)*

3. **OpenAI Function Calling Guide**
   https://platform.openai.com/docs/guides/function-calling
   *Relevance: Tool use implementation*

4. **OpenAI Embeddings Guide**
   https://platform.openai.com/docs/guides/embeddings
   *Relevance: Semantic search*

---

## Summary: Transformer Concepts Applied

| Transformer Concept | Our Application |
|---------------------|-----------------|
| Token Embeddings | Document embeddings for incidents |
| Attention Mechanism | Cosine similarity for relevance |
| Softmax Aggregation | Weighted probability calculation |
| Decoder Architecture | LLM generates reports (GPT-style) |
| Function Calling | Tool orchestration |
| Multi-step Reasoning | 3-step agent workflow |

**This project demonstrates how transformer architectures can be responsibly deployed in safety-critical domains by partnering LLM capabilities with deterministic analysis tools.**

---

**Repository:** https://github.com/Kshetkar1/NTSB-aviation-diagnosis-Transformers-Project
**Author:** Kanu Shetkar
